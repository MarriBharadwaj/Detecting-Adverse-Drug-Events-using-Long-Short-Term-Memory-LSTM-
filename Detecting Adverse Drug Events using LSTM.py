# -*- coding: utf-8 -*-
"""B21CS045_NLU_A2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15rN5pt5-o9UOQOxRu6dJobD_JLyGNLoj
"""

import pandas as pd
#importing data
data = pd.read_csv('/content/DRUG-AE (copy).txt', sep='|', names=["PubMed-ID", "Sentence", "Adverse-Effect", "Begin Offset AE", "End Offset AE", "Drug", "Begin Offset Drug", "End Offset Drug"])
data

"""Importing necessary libraries"""

import numpy as np
import re
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

"""Top 5 samples"""

data.head()

"""## Graphs"""

# @title PubMed-ID

from matplotlib import pyplot as plt
data['PubMed-ID'].plot(kind='hist', bins=20, title='PubMed-ID')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Begin Offset AE

from matplotlib import pyplot as plt
data['Begin Offset AE'].plot(kind='hist', bins=20, title='Begin Offset AE')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title End Offset AE

from matplotlib import pyplot as plt
data['End Offset AE'].plot(kind='hist', bins=20, title='End Offset AE')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Begin Offset Drug

from matplotlib import pyplot as plt
data['Begin Offset Drug'].plot(kind='hist', bins=20, title='Begin Offset Drug')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title PubMed-ID vs Begin Offset AE

from matplotlib import pyplot as plt
data.plot(kind='scatter', x='PubMed-ID', y='Begin Offset AE', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Begin Offset AE vs End Offset AE

from matplotlib import pyplot as plt
data.plot(kind='scatter', x='Begin Offset AE', y='End Offset AE', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title End Offset AE vs Begin Offset Drug

from matplotlib import pyplot as plt
data.plot(kind='scatter', x='End Offset AE', y='Begin Offset Drug', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Begin Offset Drug vs End Offset Drug

from matplotlib import pyplot as plt
data.plot(kind='scatter', x='Begin Offset Drug', y='End Offset Drug', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title PubMed-ID

from matplotlib import pyplot as plt
data['PubMed-ID'].plot(kind='line', figsize=(8, 4), title='PubMed-ID')
plt.gca().spines[['top', 'right']].set_visible(False)

# @title Begin Offset AE

from matplotlib import pyplot as plt
data['Begin Offset AE'].plot(kind='line', figsize=(8, 4), title='Begin Offset AE')
plt.gca().spines[['top', 'right']].set_visible(False)

# @title End Offset AE

from matplotlib import pyplot as plt
data['End Offset AE'].plot(kind='line', figsize=(8, 4), title='End Offset AE')
plt.gca().spines[['top', 'right']].set_visible(False)

# @title Begin Offset Drug

from matplotlib import pyplot as plt
data['Begin Offset Drug'].plot(kind='line', figsize=(8, 4), title='Begin Offset Drug')
plt.gca().spines[['top', 'right']].set_visible(False)

"""Description of the ADE dataset"""

print("Shape of the dataset:", data.shape)

print("Column names:", data.columns)

print("Data types of columns:\n", data.dtypes)

print("Number of unique values in each column:\n", data.nunique())

# Calculate co-occurrence frequencies of drug-adverse effect pairs
co_occurrence=data.groupby(['Drug', 'Adverse-Effect']).size().reset_index(name='Frequency')

#Sort by frequency to identify common associations
co_occurrence_sorted=co_occurrence.sort_values(by='Frequency', ascending=False)

# Display the top associations
print("Top Drug-Adverse Effect Associations:")
print(co_occurrence_sorted.head(10))

print("Distribution of Adverse-Effect:\n", data['Adverse-Effect'].value_counts())
print("\nDistribution of Drug:\n", data['Drug'].value_counts())

print("Missing values in each column:\n", data.isnull().sum())

"""Correlation Matrix between respective columns"""

data.corr()

"""Overall summary of dataset"""

data.describe()

"""Dropping points consisting of missing values"""

data.dropna(inplace=True)

"""## Preprocessing"""

# Preprocessing function for text
def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()
    # Remove punctuation and special characters
    text = re.sub(r"[^a-zA-Z0-9\s]", "", text)
    return text

"""Applying tokenisation"""

# Apply preprocessing to the Sentence column
data['Sentence'] = data['Sentence'].apply(preprocess_text)

# Tokenization
tokenizer = Tokenizer()
tokenizer.fit_on_texts(data['Sentence'])

# Convert text to sequences of integers
sequences = tokenizer.texts_to_sequences(data['Sentence'])

# Tokenize sentences into words
tokenized_sentences = [sentence.split() for sentence in data['Sentence']]

# Count words in each sentence
word_counts = [len(sentence) for sentence in tokenized_sentences]

# Calculate average sentence length
average_sentence_length = sum(word_counts) / len(word_counts)
print("Average Sentence Length:", average_sentence_length)

"""Understanding the lengths of sentences in the "Sentence" column to choose the optimal value for truncation"""

token_counts = data['Sentence'].apply(lambda x: len(nltk.word_tokenize(x)))

# Plot histogram
plt.figure(figsize=(8, 6))
plt.hist(token_counts, bins=range(0, max(token_counts) + 1, 1), color='skyblue', edgecolor='black')
plt.title('Distribution of Sentence Lengths')
plt.xlabel('Number of Tokens')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

"""Performing padding"""

# Padding sequences to ensure uniform length
max_seq_length = 40
padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')

"""Label-Encoding"""

# Encoding adverse effects and drugs
data['Adverse-Effect'] = pd.Categorical(data['Adverse-Effect'])
data['Drug'] = pd.Categorical(data['Drug'])

data['AE_Encoded'] = data['Adverse-Effect'].cat.codes
data['Drug_Encoded'] = data['Drug'].cat.codes

# Split dataset into train, validation, and test sets
train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)
train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)

# Convert target labels to categorical format
num_classes_ae = len(data['Adverse-Effect'].unique())
num_classes_drug = len(data['Drug'].unique())

"""Number of adverse-effects classes"""

num_classes_ae

"""Number of drug classes"""

num_classes_drug

y_train_ae = np.eye(num_classes_ae)[train_df['AE_Encoded']]
y_val_ae = np.eye(num_classes_ae)[val_df['AE_Encoded']]
y_test_ae = np.eye(num_classes_ae)[test_df['AE_Encoded']]

y_train_drug = np.eye(num_classes_drug)[train_df['Drug_Encoded']]
y_val_drug = np.eye(num_classes_drug)[val_df['Drug_Encoded']]
y_test_drug = np.eye(num_classes_drug)[test_df['Drug_Encoded']]

# Print shapes for verification
print("Padded Sequences Shape:", padded_sequences.shape)
print("Adverse Effect Labels Shape (Train):", y_train_ae.shape)
print("Drug Labels Shape (Train):", y_train_drug.shape)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
data['Adverse-Effect'].value_counts().plot(kind='bar')
plt.title('Distribution of Adverse Effects')
plt.xlabel('Adverse Effect')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(10, 5))
data['Drug'].value_counts().plot(kind='bar')
plt.title('Distribution of Drugs')
plt.xlabel('Drug')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()

"""## Heatmap"""

import seaborn as sns

plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

"""**Wordcloud**- the size of each word indicates its frequency or importance within the text"""

from wordcloud import WordCloud

text = ' '.join(data['Sentence'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.title('Word Cloud of Sentences')
plt.axis('off')
plt.show()

"""### Model Architecture"""

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Bidirectional

# Define input shape
input_shape = (max_seq_length,)

# Define the embedding layer
vocab_size = len(tokenizer.word_index) + 1  # Add 1 for padding token
embedding_dim = 100
embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_seq_length)

# Define the LSTM layer
lstm_units = 64  # Number of units in LSTM layer
lstm_layer = LSTM(units=lstm_units, return_sequences=False)

# Define input layer
input_layer = Input(shape=input_shape)

# Connect layers
embedded_sequences = embedding_layer(input_layer)
lstm_output = lstm_layer(embedded_sequences)

ae_output = Dense(num_classes_ae, activation='softmax', name='ae_output')(lstm_output)
drug_output = Dense(num_classes_drug, activation='softmax', name='drug_output')(lstm_output)

# Define the model
model = Model(inputs=input_layer, outputs=[ae_output, drug_output])

# Compile the model
model.compile(optimizer='adam',
              loss={'ae_output': 'categorical_crossentropy', 'drug_output': 'categorical_crossentropy'},
              metrics=['accuracy'])
# Print model summary
print(model.summary())

"""## Training and testing the designed LSTM model"""

# Split the dataset into training, validation, and test sets
X_train = padded_sequences[train_df.index]
X_val = padded_sequences[val_df.index]
X_test = padded_sequences[test_df.index]

y_train_ae = np.eye(num_classes_ae)[train_df['AE_Encoded']]
y_val_ae = np.eye(num_classes_ae)[val_df['AE_Encoded']]
y_test_ae = np.eye(num_classes_ae)[test_df['AE_Encoded']]

y_train_drug = np.eye(num_classes_drug)[train_df['Drug_Encoded']]
y_val_drug = np.eye(num_classes_drug)[val_df['Drug_Encoded']]
y_test_drug = np.eye(num_classes_drug)[test_df['Drug_Encoded']]

# Train the model
history = model.fit(X_train, {'ae_output': y_train_ae, 'drug_output': y_train_drug},
                    validation_data=(X_val, {'ae_output': y_val_ae, 'drug_output': y_val_drug}),
                    epochs=100, batch_size=32)

# Evaluate the model on the test set
test_results = model.evaluate(X_test, {'ae_output': y_test_ae, 'drug_output': y_test_drug}, verbose=2)
print("\nTest Loss:", test_results[0])
print("Test Accuracy (Adverse Effect):", test_results[1])
print("Test Accuracy (Drug):", test_results[2])

# Plot training and validation accuracy
plt.plot(history.history['ae_output_accuracy'], label='Adverse Effect Train Accuracy')
plt.plot(history.history['val_ae_output_accuracy'], label='Adverse Effect Validation Accuracy')
plt.plot(history.history['drug_output_accuracy'], label='Drug Train Accuracy')
plt.plot(history.history['val_drug_output_accuracy'], label='Drug Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Predictions on test set
y_pred_ae, y_pred_drug = model.predict(X_test)

# Convert predicted probabilities to class labels
y_pred_ae_class = np.argmax(y_pred_ae, axis=1)
y_pred_drug_class = np.argmax(y_pred_drug, axis=1)

# True class labels
y_true_ae = np.argmax(y_test_ae, axis=1)
y_true_drug = np.argmax(y_test_drug, axis=1)

# Evaluation metrics for Adverse Effect (AE)
print("Evaluation Metrics for Adverse Effect (AE):")
print("Accuracy:", accuracy_score(y_true_ae, y_pred_ae_class))
print("Precision:", precision_score(y_true_ae, y_pred_ae_class, average='weighted'))
print("Recall:", recall_score(y_true_ae, y_pred_ae_class, average='weighted'))
print("F1-Score:", f1_score(y_true_ae, y_pred_ae_class, average='weighted'))

# Evaluation metrics for Drug
print("\nEvaluation Metrics for Drug:")
print("Accuracy:", accuracy_score(y_true_drug, y_pred_drug_class))
print("Precision:", precision_score(y_true_drug, y_pred_drug_class, average='weighted'))
print("Recall:", recall_score(y_true_drug, y_pred_drug_class, average='weighted'))
print("F1-Score:", f1_score(y_true_drug, y_pred_drug_class, average='weighted'))

"""ROC (receiver operating characteristic)curve for AUC (area under the curve) metric"""

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Compute ROC curve and ROC area for each class
fpr_ae, tpr_ae, _ = roc_curve(y_test_ae.ravel(), y_pred_ae.ravel())
roc_auc_ae = auc(fpr_ae, tpr_ae)

fpr_drug, tpr_drug, _ = roc_curve(y_test_drug.ravel(), y_pred_drug.ravel())
roc_auc_drug = auc(fpr_drug, tpr_drug)

# Plot ROC curve for Adverse Effect (AE)
plt.figure()
plt.plot(fpr_ae, tpr_ae, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_ae)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic for Adverse Effect (AE)')
plt.legend(loc="lower right")
plt.show()

# Plot ROC curve for Drug
plt.figure()
plt.plot(fpr_drug, tpr_drug, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_drug)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic for Drug')
plt.legend(loc="lower right")
plt.show()

print("Here the blue line represents the roc of a random classifier, hence making it optimal to compare the actual ROC to!")
